# Week 1: Tokenization & TF-IDF
## Libraries
- `nltk`
- `sklearn.feature_extraction.text`

## Notes
- Tokenization splits text into words.
- Stopword removal helps clean noise.
- Lemmatization converts words to base form (e.g. “running” → “run”).
- TF-IDF helps assign importance to words in documents based on frequency.
